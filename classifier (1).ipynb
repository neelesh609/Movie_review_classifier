{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy as sp\nimport csv\nimport nltk\nimport pickle\nimport operator\nimport tkinter as tk\nfrom tkinter import *\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\n\nimport time\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading the train data and the test data**","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/imdb-50k-movie-reviews-test-your-bert/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/imdb-50k-movie-reviews-test-your-bert/test.csv\")\n\nmovie_data = [train_data,test_data]\nfinal_data = pd.concat(movie_data)\n\nsplit_1 = int(0.8 * len(final_data))\nsplit_2 = int(0.9 * len(final_data))\ntrain_data = final_data[:split_1]\ndev_data = final_data[split_1:split_2]\ntest_data = final_data[split_2:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_data.info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We add another column sentiment_int where the negative comments are branded as 0 and the positive comments are branded as 1 **","metadata":{}},{"cell_type":"code","source":"train_data.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head(5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_data.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment_int = []\nfor index, row  in train_data.iterrows():\n    if row['sentiment'] == 'pos':\n        sentiment_int.append(1)\n    else:\n        sentiment_int.append(0)\n\ntrain_data[\"sentiment_int\"] = sentiment_int\n\n\nsentiment_int = []\nfor index, row  in test_data.iterrows():\n    if row['sentiment'] == 'pos':\n        sentiment_int.append(1)\n    else:\n        sentiment_int.append(0)\n\ntest_data[\"sentiment_int\"] = sentiment_int\n\n\nsentiment_int = []\nfor index, row  in dev_data.iterrows():\n    if row['sentiment'] == 'pos':\n        sentiment_int.append(1)\n    else:\n        sentiment_int.append(0)\n\ndev_data[\"sentiment_int\"] = sentiment_int","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nRow, nCol = train_data.shape\nprint(f'There are {nRow} rows and {nCol} columns of training data') \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nRow, nCol = test_data.shape\nprint(f'There are {nRow} rows and {nCol} columns of test data')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nRow, nCol = dev_data.shape\nprint(f'There are {nRow} rows and {nCol} columns of development data')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['sentiment_int'].plot.hist()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['sentiment_int'].plot.hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_data['sentiment_int'].plot.hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_len = len(train_data)\nprint('total train records:', train_len)\n\npos_len = len(train_data[train_data['sentiment_int'] == 1])\nneg_len = len(train_data[train_data['sentiment_int'] == 0])\n\nprint ('positive records:', pos_len)\nprint ('negative records:', neg_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_len = len(test_data)\nprint('total train records:', test_len)\n\npos_len = len(test_data[test_data['sentiment_int'] == 1])\nneg_len = len(test_data[test_data['sentiment_int'] == 0])\n\nprint ('positive records:', pos_len)\nprint ('negative records:', neg_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_len = len(dev_data)\nprint('total train records:', dev_len)\n\npos_len = len(dev_data[dev_data['sentiment_int'] == 1])\nneg_len = len(dev_data[dev_data['sentiment_int'] == 0])\n\nprint ('positive records:', pos_len)\nprint ('negative records:', neg_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We now check for any duplicate data and thus remove it as it might affect the accuracy**","metadata":{}},{"cell_type":"code","source":"print(f'Number of duplicates in the data = {train_data.duplicated().sum()}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_train = train_data.drop_duplicates(subset=None, keep='first')\nmovie_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of duplicates in the data = {test_data.duplicated().sum()}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_test = test_data.drop_duplicates(subset=None, keep='first')\nmovie_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of duplicates in the data = {dev_data.duplicated().sum()}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_dev = dev_data.drop_duplicates(subset=None, keep='first')\nmovie_dev","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now we check if there is any sparse data and thus remove them , but luckily we do not have any sparse data**","metadata":{}},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[\"text\"] = train_data[\"text\"].str.lower()\ntrain_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratings_counts = train_data['sentiment_int'].value_counts().sort_index(ascending=False)\nprint(\"Count of each rating value:\\n\", ratings_counts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratings_count_list = sorted(ratings_counts.items(), key=operator.itemgetter(1), reverse=False)\nmin_count = ratings_count_list[0][1]\n\nratings_count_list = sorted(ratings_counts.items(), key=operator.itemgetter(1), reverse=True)\nmax_count = ratings_count_list[0][1]\n\nratings_count_list = sorted(ratings_counts.items(), key=operator.itemgetter(0), reverse=False)\n\nratingVal = [item[0] for item in ratings_count_list]\ncountVal = [item[1] for item in ratings_count_list]\n\ndf = pd.DataFrame({'Rating Count': countVal}, index=ratingVal)\n\nax = df.plot.bar(rot=0)\nax.set(ylim=[min_count-10000, max_count+5000])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"small_df = train_data.groupby('sentiment_int').apply(lambda x: x.sample(frac=0.8))\noriginal_len_small_df = len(small_df)\nprint(original_len_small_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now we implement mutiple classifiers**","metadata":{}},{"cell_type":"code","source":"tfidfconverter = TfidfVectorizer(min_df=0.002)\n\n# For train data - use fit_transform\nX_train = tfidfconverter.fit_transform(train_data['text']).toarray()\n\n# For dev and test - use transform\nX_dev_arr = tfidfconverter.transform(dev_data['text']).toarray()\nX_test_arr = tfidfconverter.transform(test_data['text']).toarray()\nX_dev = tfidfconverter.transform(dev_data['text'])\nX_test = tfidfconverter.transform(test_data['text'])\n\n# Put 'rating' column of each dataframe into y\ny_train = np.asarray(train_data['sentiment_int'])\ny_dev = np.asarray(dev_data['sentiment_int'])\ny_test = np.asarray(test_data['sentiment_int'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mse_dict = dict()\naccuracy_dict = dict()\nclassifier_dict = dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First we implement Naive Bayes classifier","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\n# Train and Predict the data using Multinomial Naive Bayes\nmultinomialNB = MultinomialNB(alpha=1)\nmultinomialNB.fit(X_train, y_train)\nclassifier_dict[\"Multinomial Naive Bayes\"] = multinomialNB;\ny_pred_mnb_dev = multinomialNB.predict(X_dev)\n\n# Calculate the Mean Squared Error and Accuracy\nmse_mnb_dev = mean_squared_error(y_test, y_pred_mnb_dev)\naccuracy_mnb_dev = accuracy_score(y_test, y_pred_mnb_dev)*100\n\n# Print the Mean Squared Error and Accuracy\nprint(\"Using Multinomial Naive Bayes:\")\nprint(\"Mean Squared Error:\", mse_mnb_dev)\nprint(\"Accuracy:\", accuracy_mnb_dev)\n\n# Store the Mean Squared Error and Accuracy in dictionaries\nmse_dict[\"Multinomial Naive Bayes\"] = mse_mnb_dev;\naccuracy_dict[\"Multinomial Naive Bayes\"] = accuracy_mnb_dev;\n\nend_time = time.time()\nprint(\"runtime: %s sec\" % (end_time - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We implement Support vector Machine SVM classifier**","metadata":{}},{"cell_type":"markdown","source":"SVM where c=1","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\n# Train and Predict the data using Linear SVM (C=1)\nlinearSVC1 = LinearSVC(C=1, dual=False)\nlinearSVC1.fit(X_train, y_train)\nclassifier_dict[\"Linear SVC (C=1)\"] = linearSVC1;\ny_pred_lsvc = linearSVC1.predict(X_dev)\n\n# Calculate the Mean Squared Error and Accuracy\nmse_lsvc1_dev = mean_squared_error(y_test, y_pred_lsvc)\naccuracy_lsvc1_dev = accuracy_score(y_test, y_pred_lsvc)*100\n\n# Print the Mean Squared Error and Accuracy\nprint(\"Using Linear SVC (C=1):\")\nprint('Mean Squared Error:', mse_lsvc1_dev)\nprint('Accuracy:', accuracy_lsvc1_dev)\n\n# Store the Mean Squared Error and Accuracy in dictionaries\nmse_dict[\"Linear SVC (C=1)\"] = mse_lsvc1_dev;\naccuracy_dict[\"Linear SVC (C=1)\"] = accuracy_lsvc1_dev;\n\nend_time = time.time()\nprint(\"runtime: %s sec\" % (end_time - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Svm where c = 100","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\n# Train and Predict the data using Linear SVM (C=100)\nlinearSVC100 = LinearSVC(C=100, dual=False)\nlinearSVC100.fit(X_train, y_train)\nclassifier_dict[\"Linear SVC (C=100)\"] = linearSVC100;\ny_pred_lsvc = linearSVC100.predict(X_dev)\n\n# Calculate the Mean Squared Error and Accuracy\nmse_lsvc100_dev = mean_squared_error(y_test, y_pred_lsvc)\naccuracy_lsvc100_dev = accuracy_score(y_test, y_pred_lsvc)*100\n\n# Print the Mean Squared Error and Accuracy\nprint(\"Using Linear SVC (C=100):\")\nprint('Mean Squared Error:', mse_lsvc100_dev)\nprint('Accuracy:', accuracy_lsvc100_dev)\n\n# Store the Mean Squared Error and Accuracy in dictionaries\nmse_dict[\"Linear SVC (C=100)\"] = mse_lsvc100_dev;\naccuracy_dict[\"Linear SVC (C=100)\"] = accuracy_lsvc100_dev;\n\nend_time = time.time()\nprint(\"runtime: %s sec\" % (end_time - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Svm where c=1000","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\n# Train and Predict the data using Linear SVM (C=1000)\nlinearSVC1000 = LinearSVC(C=1000, dual=False)\nlinearSVC1000.fit(X_train, y_train)\nclassifier_dict[\"Linear SVC (C=1000)\"] = linearSVC1000;\ny_pred_lsvc = linearSVC1000.predict(X_dev)\n\n# Calculate the Mean Squared Error and Accuracy\nmse_lsvc1000_dev = mean_squared_error(y_test, y_pred_lsvc)\naccuracy_lsvc1000_dev = accuracy_score(y_test, y_pred_lsvc)*100\n\n# Print the Mean Squared Error and Accuracy\nprint(\"Using Linear SVC (C=1000):\")\nprint('Mean Squared Error:', mse_lsvc1000_dev)\nprint('Accuracy:', accuracy_lsvc1000_dev)\n\n# Store the Mean Squared Error and Accuracy in dictionaries\nmse_dict[\"Linear SVC (C=1000)\"] = mse_lsvc1000_dev;\naccuracy_dict[\"Linear SVC (C=1000)\"] = accuracy_lsvc1000_dev;\n\nend_time = time.time()\nprint(\"runtime: %s sec\" % (end_time - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RandomForest Classifier**","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\n# Train and Predict the data using Random Forest Classifier (n_estimators=10)\nrandomForest10 = RandomForestClassifier(max_depth=100, n_estimators=10, max_features=1)\nrandomForest10.fit(X_train, y_train)\nclassifier_dict[\"Random Forest Classifier (n_estimators=10)\"] = randomForest10;\ny_pred_rfc = randomForest10.predict(X_dev)\n\n# Calculate the Accuracy\nmse_rfc10_dev = mean_squared_error(y_test, y_pred_rfc)\naccuracy_rfc10_dev = accuracy_score(y_test, y_pred_rfc)*100\n\n# Print the  and Accuracy\nprint(\"Using Random Forest Classifier:\")\n\nprint('Accuracy:', accuracy_rfc10_dev)\n\n# Store the Mean Squared Error and Accuracy in dictionaries\nmse_dict[\"Random Forest Classifier (n_estimators=10)\"] = mse_rfc10_dev;\naccuracy_dict[\"Random Forest Classifier (n_estimators=10)\"] = accuracy_rfc10_dev;\n\nend_time = time.time()\nprint(\"runtime: %s sec\" % (end_time - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\n# Train and Predict the data using Linear SVM (n_estimators=50)\nrandomForest50 = RandomForestClassifier(max_depth=100, n_estimators=50, max_features=1)\nrandomForest50.fit(X_train, y_train)\nclassifier_dict[\"Random Forest Classifier (n_estimators=50)\"] = randomForest50;\ny_pred_rfc = randomForest50.predict(X_dev)\n\n# Calculate the Mean Squared Error and Accuracy\nmse_rfc50_dev = mean_squared_error(y_test, y_pred_rfc)\naccuracy_rfc50_dev = accuracy_score(y_test, y_pred_rfc)*100\n\n# Print the Mean Squared Error and Accuracy\nprint(\"Using Random Forest Classifier (n_estimators=50):\")\nprint('Mean Squared Error:', mse_rfc50_dev)\nprint('Accuracy:', accuracy_rfc50_dev)\n\n# Store the Mean Squared Error and Accuracy in dictionaries\nmse_dict[\"Random Forest Classifier (n_estimators=50)\"] = mse_rfc50_dev;\naccuracy_dict[\"Random Forest Classifier (n_estimators=50)\"] = accuracy_rfc50_dev;\n\nend_time = time.time()\nprint(\"runtime: %s sec\" % (end_time - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparing the accuracies of all the classifiers","metadata":{}},{"cell_type":"code","source":"mse_dict_list = sorted(mse_dict.items(), key=operator.itemgetter(1), reverse=False)\naccuracy_dict_list = sorted(accuracy_dict.items(), key=operator.itemgetter(1), reverse=True)\naccuracy_dict_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph_accuracy_list = [item[1] for item in accuracy_dict_list]\ngraph_classifier_list = [item[0] for item in mse_dict_list]\ngraph_mse_list = [item[1] for item in mse_dict_list]\n\nminY = 0;\nmaxY = max(graph_accuracy_list)\n\ndf = pd.DataFrame({'Accuracy': graph_accuracy_list}, index=graph_classifier_list)\nax = df.plot(figsize=(7,5), kind='bar', stacked=True)\n\nax. set(xlabel=\"Classifiers used\", ylabel=\"Accuracy\")\n\nax.set(ylim=[minY, maxY+2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Best Classifer**","metadata":{}},{"cell_type":"code","source":"highest_accuracy_classifier = accuracy_dict_list[0]\nprint(\"Best Classifier considering highest accuracy:\", highest_accuracy_classifier)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_classifier_name = accuracy_dict_list[0][0]\nbestClassifier = classifier_dict.get(best_classifier_name)\nprint(bestClassifier)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test = bestClassifier.predict(X_test)\naccuracy_test = accuracy_score(y_test, y_pred_test)*100\nprint(\"Using Best Classifier:\\n\")\nprint('Accuracy:', accuracy_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_review = input('Enter your review: ') \nmcom = {'text': [input_review]}\nmdf = pd.DataFrame(mcom, columns = ['text'])\nX_single = tfidfconverter.transform(mdf['text'])\ny_single = bestClassifier.predict(X_single)\nprint(\"review: \", y_single[0])\nif y_single == 1:\n    print('positive review')\nelse:\n    print('Negative')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}